{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install autogen\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1f-HXyYIUkp",
        "outputId": "40be8841-cb46-485b-9477-9f137dbc6d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogen in /usr/local/lib/python3.11/dist-packages (0.7.5)\n",
            "Requirement already satisfied: pyautogen==0.7.5 in /usr/local/lib/python3.11/dist-packages (from autogen) (0.7.5)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (0.0.8)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (7.1.0)\n",
            "Requirement already satisfied: fast-depends<3,>=2.4.12 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (2.4.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.58 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (1.61.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (2.10.6)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (1.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (2.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (0.9.0)\n",
            "Requirement already satisfied: websockets<15,>=14 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.5->autogen) (14.2)\n",
            "Requirement already satisfied: anyio<5.0,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from asyncer==0.0.8->pyautogen==0.7.5->autogen) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen==0.7.5->autogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen==0.7.5->autogen) (2.27.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyautogen==0.7.5->autogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyautogen==0.7.5->autogen) (2.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->pyautogen==0.7.5->autogen) (2024.11.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.4.0->asyncer==0.0.8->pyautogen==0.7.5->autogen) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.5->autogen) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.5->autogen) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.5->autogen) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->pyautogen==0.7.5->autogen) (3.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY =  userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "BbyNepRBKGaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(OPENAI_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNLo8_dhKXAi",
        "outputId": "3cff7cd1-dfb6-43a8-f6dd-5ede268e94dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "import json\n",
        "import autogen\n",
        "config_list_data = [\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"api_key\": OPENAI_API_KEY,\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gpt-4-0314\",\n",
        "       \"api_key\": OPENAI_API_KEY,\n",
        "    },\n",
        "       {\n",
        "        \"model\": \"gpt4\",\n",
        "       \"api_key\": OPENAI_API_KEY,\n",
        "    },\n",
        "       {\n",
        "        \"model\": \"gpt-4-32k\",\n",
        "       \"api_key\": OPENAI_API_KEY,\n",
        "    },\n",
        "      {\n",
        "        \"model\": \"gpt-4-32k-0314\",\n",
        "       \"api_key\": OPENAI_API_KEY,\n",
        "    },\n",
        "      {\n",
        "        \"model\": \"gpt-4-32k-v0314\",\n",
        "       \"api_key\": OPENAI_API_KEY,\n",
        "    }\n",
        "]\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "14m84SaQJxeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config_list_json = json.dumps(config_list_data)\n",
        "os.environ[\"OAI_CONFIG_LIST\"] = config_list_json\n",
        "config_list = autogen.config_list_from_json(\n",
        "    env_or_file=\"OAI_CONFIG_LIST\",\n",
        "    filter_dict={\n",
        "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "9LJz4FZnJLJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = {\"config_list\": config_list, \"cache_seed\": 42}\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"User_proxy\",\n",
        "    system_message=\"A human admin.\",\n",
        "    code_execution_config={\n",
        "        \"last_n_messages\": 2,\n",
        "        \"work_dir\": \"groupchat\",\n",
        "        \"use_docker\": False,\n",
        "    },\n",
        "    human_input_mode=\"TERMINATE\",\n",
        ")\n",
        "coder = autogen.AssistantAgent(\n",
        "    name=\"Coder\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "pm = autogen.AssistantAgent(\n",
        "    name=\"Product_manager\",\n",
        "    system_message=\"Creative in software product ideas.\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
      ],
      "metadata": {
        "id": "WWhuSQxsKkAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = user_proxy.initiate_chat(\n",
        "    manager, message=\"Find a recent paper on multimodal GPT models. Then, explain how such a model could improve AI-powered code review tools.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2l4TSzVKwhX",
        "outputId": "9ed0b68d-93fe-423e-f794-2cb3c6beedc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User_proxy (to chat_manager):\n",
            "\n",
            "Find a recent paper on multimodal GPT models. Then, explain how such a model could improve AI-powered code review tools.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: Coder\n",
            "\n",
            "Coder (to chat_manager):\n",
            "\n",
            "To achieve this, our steps will be as follows:\n",
            "\n",
            "1. Browse the internet for a recent paper on multimodal GPT models.\n",
            "2. Read and understand the paper to ascertain how such a model could improve AI-powered code review tools.\n",
            "\n",
            "To step 1, I'll write Python code using the Google Scholar library, BeautifulSoup, and requests library to search and scrape the title and link of the most recent paper on \"multimodal GPT models\". \n",
            "\n",
            "Please execute the following Python script:\n",
            "```python\n",
            "#python code\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "import scholarly\n",
            "\n",
            "def find_paper(query):\n",
            "    search_query = scholarly.search_pubs(query)\n",
            "    paper = next(search_query)\n",
            "    return paper.bib['title'], paper.bib['url']\n",
            "\n",
            "query = \"multimodal GPT models\"\n",
            "title, url = find_paper(query)\n",
            "print(\"The most recent paper is:\", title)\n",
            "print(\"The paper can be found at:\", url)\n",
            "```\n",
            "This script will output the most recent paper's title and URL. I will analyze this information and then provide information on how multimodal GPT models can improve AI-powered code review tools.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: User_proxy\n",
            "\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n",
            "User_proxy (to chat_manager):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "Traceback (most recent call last):\n",
            "  File \"\", line 4, in <module>\n",
            "    import scholarly\n",
            "ModuleNotFoundError: No module named 'scholarly'\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: Coder\n",
            "\n",
            "Coder (to chat_manager):\n",
            "\n",
            "It seems you don't have the 'scholarly' package installed in your Python environment. \n",
            "\n",
            "Let's modify this approach and use the 'requests' and 'BeautifulSoup' packages to scrape Google Scholar directly instead. This approach avoids the need for the 'scholarly' package.\n",
            "\n",
            "This new Python code will search for papers on \"multimodal GPT models\" and return the title and link of the most recent one. \n",
            "\n",
            "Please execute the following Python script:\n",
            "\n",
            "```python\n",
            "#python code\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "\n",
            "def find_paper(query):\n",
            "    url = f\"https://scholar.google.com/scholar?as_ylo={datetime.now().year}&q={query.replace(' ', '+')}\"\n",
            "    response = requests.get(url)\n",
            "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
            "    first_result = soup.find(\"h3\", class_=\"gs_rt\")\n",
            "    title, url = first_result.text, first_result.a['href']\n",
            "    return title, url\n",
            "\n",
            "query = \"multimodal GPT models\"\n",
            "title, url = find_paper(query)\n",
            "print(\"The most recent paper is:\", title)\n",
            "print(\"The paper can be found at:\", url)\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: User_proxy\n",
            "\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n",
            "User_proxy (to chat_manager):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "Traceback (most recent call last):\n",
            "  File \"\", line 14, in <module>\n",
            "    title, url = find_paper(query)\n",
            "                 ^^^^^^^^^^^^^^^^^\n",
            "  File \"\", line 6, in find_paper\n",
            "    url = f\"https://scholar.google.com/scholar?as_ylo={datetime.now().year}&q={query.replace(' ', '+')}\"\n",
            "                                                       ^^^^^^^^\n",
            "NameError: name 'datetime' is not defined\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: Coder\n",
            "\n",
            "Coder (to chat_manager):\n",
            "\n",
            "It seems I forgot to import the datetime module. Sorry about the oversight. \n",
            "\n",
            "Here is the corrected code. It imports the necessary datetime module to get the current year. The rest of the code is identical to the previous version.\n",
            "\n",
            "```python\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "from datetime import datetime\n",
            "\n",
            "def find_paper(query):\n",
            "    url = f\"https://scholar.google.com/scholar?as_ylo={datetime.now().year}&q={query.replace(' ', '+')}\"\n",
            "    response = requests.get(url)\n",
            "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
            "    first_result = soup.find(\"h3\", class_=\"gs_rt\")\n",
            "    title = first_result.text\n",
            "    url = first_result.a['href']\n",
            "    return title, url\n",
            "\n",
            "query = \"multimodal GPT models\"\n",
            "title, url = find_paper(query)\n",
            "print(\"The most recent paper is:\", title)\n",
            "print(\"The paper can be found at:\", url)\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: User_proxy\n",
            "\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n",
            "User_proxy (to chat_manager):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: \n",
            "The most recent paper is: Impact of Multimodal Prompt Elements on Diagnostic Performance of GPT-4V in Challenging Brain MRI Cases\n",
            "The paper can be found at: https://pubs.rsna.org/doi/abs/10.1148/radiol.240689\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: Coder\n",
            "\n",
            "Coder (to chat_manager):\n",
            "\n",
            "Thank you for executing the code. The most recent paper found on \"multimodal GPT models\" is \"Impact of Multimodal Prompt Elements on Diagnostic Performance of GPT-4V in Challenging Brain MRI Cases\". Here is the link to the paper: [Link to the paper](https://pubs.rsna.org/doi/abs/10.1148/radiol.240689)\n",
            "\n",
            "Based on the title, it appears this paper is more focused on medical imaging. Nevertheless, the principles of multimodal GPT models (Generative Pretrained Transformers) can be applied to other areas as well, including code review tools.\n",
            "\n",
            "In the context of AI-powered code review tools, multimodal GPT models could enhance performance in several ways:\n",
            "\n",
            "1. **Understand Context Better**: Multimodal models take in multiple forms of input, in case of code review tools it can be both the code and the comments. By processing these inputs concurrently, the model will have better context, leading to improved identification of multiple types of errors, be it syntax, performance issues, or even non-functional requirements like readability and quality of comments.\n",
            "\n",
            "2. **Generate Richer Responses**: Multimodal GPT models can generate more detailed and relevant responses. For instance, when identifying an issue, it can provide textual explanation and code correction simultaneously.\n",
            "\n",
            "3. **Constant Learning and Improvement**: GPT models are pretrained on massive datasets and are based on machine learning, hence, they improve their performance continually as they process more and more code, learning from previous corrections and developer feedback.\n",
            "\n",
            "It's important to consider that despite these potential advantages, multimodal GPT models might also introduce challenges such as increased complexity and computational demands. Also, these models are based on current ML understanding and can be wrong, therefore, results should always be checked and validated by human reviewers.\n",
            "\n",
            "Specifics would be available in the paper, and they would provide a more detailed insight into the benefits and perhaps methods of integrating multimodal GPT models into code review tools.\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: Product_manager\n",
            "\n",
            "Product_manager (to chat_manager):\n",
            "\n",
            "The most recent paper found on \"multimodal GPT models\" is the \"Impact of Multimodal Prompt Elements on Diagnostic Performance of GPT-4V in Challenging Brain MRI Cases\". \n",
            "\n",
            "However, this paper is more focused on medical imaging and may not directly relate to the improvement of AI-powered code review tools. Therefore, lets discuss theoretical applications of a multimodal GPT model in code review tools. \n",
            "\n",
            "Here's how such a model may improve these tools:\n",
            "\n",
            "1. **Understand Context Better**: GPT models like the one discussed in the paper are able to take in multiple types of input. For code review tools, this could mean processing both the written code and any associated comments or documentation simultaneously. This could provide the model with a better context, allowing it to more effectively identify various types of errors including, but not limited to, syntax errors, performance issues, or even readability and maintainability issues.\n",
            "\n",
            "2. **Generate Richer Responses**: Because of its input capabilities, a multimodal GPT model might also be able to generate more detailed responses. For example, if it identifies an issue within the code, it can provide an in-depth description of the issue, guidance on how to fix it, and even tweak or re-write sections of the code automatically.\n",
            "\n",
            "3. **Constant Learning and Improvement**: GPT models are pretrained on large volumes of data and improve based on the feedback they receive. This means that over time, as the model processes more code and receives feedback from developers, its performance will improve, comments will become more precise and it may start identifying more complex bugs and issues.\n",
            "\n",
            "It's important to note that while the potential for improvement is significant, a multimodal GPT model may also come with its own challenges. It could introduce more complexity and require higher computational power amongst other potential issues. Therefore, it's crucial to combine this tool with the human element, ensuring that there is always a developer involved in the review process to catch any errors or anomalies that the AI might miss. \n",
            "\n",
            "To get detailed insights into how exactly the use of multimodal GPT models could be optimised for this context, we'd recommend reaching out to an expert in AI or Machine Learning or referring to more specialist sources.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: User_proxy\n",
            "\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "User_proxy (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: User_proxy\n",
            "\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "User_proxy (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: Coder\n",
            "\n",
            "Coder (to chat_manager):\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.chat_history[-4]['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "X7xa9otPRfQv",
        "outputId": "6c1c1994-eb25-4c49-8fa9-b1a8235b1019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The most recent paper found on \"multimodal GPT models\" is the \"Impact of Multimodal Prompt Elements on Diagnostic Performance of GPT-4V in Challenging Brain MRI Cases\". \\n\\nHowever, this paper is more focused on medical imaging and may not directly relate to the improvement of AI-powered code review tools. Therefore, lets discuss theoretical applications of a multimodal GPT model in code review tools. \\n\\nHere\\'s how such a model may improve these tools:\\n\\n1. **Understand Context Better**: GPT models like the one discussed in the paper are able to take in multiple types of input. For code review tools, this could mean processing both the written code and any associated comments or documentation simultaneously. This could provide the model with a better context, allowing it to more effectively identify various types of errors including, but not limited to, syntax errors, performance issues, or even readability and maintainability issues.\\n\\n2. **Generate Richer Responses**: Because of its input capabilities, a multimodal GPT model might also be able to generate more detailed responses. For example, if it identifies an issue within the code, it can provide an in-depth description of the issue, guidance on how to fix it, and even tweak or re-write sections of the code automatically.\\n\\n3. **Constant Learning and Improvement**: GPT models are pretrained on large volumes of data and improve based on the feedback they receive. This means that over time, as the model processes more code and receives feedback from developers, its performance will improve, comments will become more precise and it may start identifying more complex bugs and issues.\\n\\nIt\\'s important to note that while the potential for improvement is significant, a multimodal GPT model may also come with its own challenges. It could introduce more complexity and require higher computational power amongst other potential issues. Therefore, it\\'s crucial to combine this tool with the human element, ensuring that there is always a developer involved in the review process to catch any errors or anomalies that the AI might miss. \\n\\nTo get detailed insights into how exactly the use of multimodal GPT models could be optimised for this context, we\\'d recommend reaching out to an expert in AI or Machine Learning or referring to more specialist sources.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most recent paper found on \"multimodal GPT models\" is the \"Impact of Multimodal Prompt Elements on Diagnostic Performance of GPT-4V in Challenging Brain MRI Cases\".\n",
        "\n",
        "However, this paper is more focused on medical imaging and may not directly relate to the improvement of AI-powered code review tools. Therefore, lets discuss theoretical applications of a multimodal GPT model in code review tools.\n",
        "\n",
        "Here's how such a model may improve these tools:\n",
        "\n",
        "1. **Understand Context Better**: GPT models like the one discussed in the paper are able to take in multiple types of input. For code review tools, this could mean processing both the written code and any associated comments or documentation simultaneously. This could provide the model with a better context, allowing it to more effectively identify various types of errors including, but not limited to, syntax errors, performance issues, or even readability and maintainability issues.\n",
        "\n",
        "2. **Generate Richer Responses**: Because of its input capabilities, a multimodal GPT model might also be able to generate more detailed responses. For example, if it identifies an issue within the code, it can provide an in-depth description of the issue, guidance on how to fix it, and even tweak or re-write sections of the code automatically.\n",
        "\n",
        "3. **Constant Learning and Improvement**: GPT models are pretrained on large volumes of data and improve based on the feedback they receive. This means that over time, as the model processes more code and receives feedback from developers, its performance will improve, comments will become more precise and it may start identifying more complex bugs and issues.\n",
        "\n",
        "It's important to note that while the potential for improvement is significant, a multimodal GPT model may also come with its own challenges. It could introduce more complexity and require higher computational power amongst other potential issues. Therefore, it's crucial to combine this tool with the human element, ensuring that there is always a developer involved in the review process to catch any errors or anomalies that the AI might miss.\n",
        "\n",
        "To get detailed insights into how exactly the use of multimodal GPT models could be optimised for this context, we'd recommend reaching out to an expert in AI or Machine Learning or referring to more specialist sources."
      ],
      "metadata": {
        "id": "SaQd0he0THD6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6_qf2-2Sp-4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}